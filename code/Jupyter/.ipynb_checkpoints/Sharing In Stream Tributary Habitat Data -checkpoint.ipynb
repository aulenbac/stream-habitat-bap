{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'leaflet' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\rscully\\AppData\\Local\\Temp\\1\\RtmpgTjMrL\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'leaflet' was built under R version 3.6.2\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package or namespace load failed for 'leaflet' in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n namespace 'htmltools' 0.3.6 is already loaded, but >= 0.4.0 is required\n",
     "output_type": "error",
     "traceback": [
      "Error: package or namespace load failed for 'leaflet' in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n namespace 'htmltools' 0.3.6 is already loaded, but >= 0.4.0 is required\nTraceback:\n",
      "1. library(leaflet)",
      "2. tryCatch({\n .     attr(package, \"LibPath\") <- which.lib.loc\n .     ns <- loadNamespace(package, lib.loc)\n .     env <- attachNamespace(ns, pos = pos, deps, exclude, include.only)\n . }, error = function(e) {\n .     P <- if (!is.null(cc <- conditionCall(e))) \n .         paste(\" in\", deparse(cc)[1L])\n .     else \"\"\n .     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n .         sQuote(package), P, conditionMessage(e))\n .     if (logical.return) \n .         message(paste(\"Error:\", msg), domain = NA)\n .     else stop(msg, call. = FALSE, domain = NA)\n . })",
      "3. tryCatchList(expr, classes, parentenv, handlers)",
      "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "5. value[[3L]](cond)",
      "6. stop(msg, call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "install.packages(\"leaflet\")\n",
    "library(leaflet)\n",
    "install.packages(\"sp\")\n",
    "library(sp)\n",
    "install.packages(\"sf\")\n",
    "library(sf)\n",
    "install.packages(\"tidyverse\")\n",
    "library(tidyverse)\n",
    "install.packages(\"rgdal\")\n",
    "library(rgdal)\n",
    "install.packages(\"formattable\")\n",
    "install.packages(\"kableExtra\")\n",
    "install.packages(\"DT\")\n",
    "library(DT)\n",
    "install.packages(\"downloader\")\n",
    "library(downloader)\n",
    "install.packages(\"RCurl\")\n",
    "library(RCurl)\n",
    "\n",
    "install.packages(\"openxlsx\")\n",
    "library(openxlsx)\n",
    "library(rstudioapi)\n",
    "library(ggplot2)\n",
    "library(formattable)\n",
    "library(htmltools)\n",
    "\n",
    "#Packages to create well formated tables in RStuido \n",
    "install.packages(\"knitr\")\n",
    "library(knitr)\n",
    "library(gridExtra)\n",
    "library(kableExtra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background \n",
    "\n",
    "To accelerate research and decision making data needs to be findable, accessible, interoperable, and reusable (FAIR). Multiple federal, state and tribal agencies collect in-stream and riparian habitat metrics to answer management questions specific to their program goals. This analysis package integrates data from two different aquatic monitoring programs; BLM AIM and EPA Rivers and Streams (Table1). \n",
    "\n",
    "<h2>Monitoring Program Information</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'xlsx' is in use and will not be installed\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"q\"\n"
     ]
    }
   ],
   "source": [
    "#program_info<-(read.xlsx(\"C:/Users/rscully/Documents/Projects/Habitat Data Sharing/\n",
    " #                           2019 Work/Code/tributary-habitat-data-sharing-/Data/Metadata.xlsx\", 1))\n",
    "\n",
    "install.packages(\"xlsx\")\n",
    "library(xlsx)\n",
    "print(\"q\")\n",
    "\n",
    "#program_info<-(read.xlsx('C:\\Users\\rscully\\Documents\\Projects\\Habitat Data Sharing\\2019 Work\\Code\\tributary-habitat-data-sharing-\\Data\\Metadata.xlsx')\n",
    "#head(program_info)               \n",
    "               \n",
    "\n",
    "#\"C:/Users/rscully/Documents/Projects/Habitat Data Sharing/2019 Work/Code/tributary-habitat-data-sharing-/Data/Metadata.xlsx\"\n",
    "\n",
    "#kable(program_info) %>%\n",
    "#    kable_styling(bootstrap_options = c(\"striped\", \"hover\", fixed_header=TRUE ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Program Metrics </h3> \n",
    "Each monitoring program calculates a standard set of metrics based on their user's needs. Metadata for the EPA and BLM can be found on their webpages, PIBO and AREMP is aviable apon request. To facilitate data sharing we compiled a data dictionary identifing the metrics calculate by more then one program. You can find the full metric table in !!!! (NEED TO REVIEW AND PUBLISH) We classified each metirc into a catagory, table 2 shows the count of metrics by catagory. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data dictionary \n",
    "metadata <-as_tibble(read.xlsx(\"Data/Metadata.xlsx\", 2))\n",
    "\n",
    "kable(metadata %>%\n",
    "  group_by(Category)%>%\n",
    "  count(Category, sort=TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each program calculates a produce a standard set of metrics. The EPA, BLM data and metadata is publicaly av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"Code/data_organize/create_list_of_metrics.R\")\n",
    "metrics_list=metrics()\n",
    "kable(metrics_list)%>%\n",
    "    kable_styling(bootstrap_options = c(\"striped\", \"hover\", fixed_header=TRUE ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources \n",
    "## Metric Data \n",
    "\n",
    "Two of the four habitat programs store metric level data online. We pull that data from the sourcs to be used to create a singular data set for mapping and analysis. \n",
    "\n",
    "<h3> BLM AIM Data </h3>\n",
    "The BLM AIM collects data across BLM lands. BLM data is stored as a geodatabase at !!!!!!!. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in download.file(url, method = method, ...): cannot open destfile 'Data/BLM.zip', reason 'No such file or directory'\n",
     "output_type": "error",
     "traceback": [
      "Error in download.file(url, method = method, ...): cannot open destfile 'Data/BLM.zip', reason 'No such file or directory'\nTraceback:\n",
      "1. download(fileURL, \"Data/BLM.zip\")",
      "2. suppressWarnings(download.file(url, method = method, ...))",
      "3. withCallingHandlers(expr, warning = function(w) invokeRestart(\"muffleWarning\"))",
      "4. download.file(url, method = method, ...)"
     ]
    }
   ],
   "source": [
    "#URL Location of the AIM GeoDataBase if the location changes this will need to be updated \n",
    "fileURL<- \"https://gis.blm.gov/AIMDownload/LayerPackages/BLM_AIM_AquADat.zip\"\n",
    "\n",
    "#Download the file to the Data file\n",
    "download(fileURL, \"Data/BLM.zip\" )\n",
    "\n",
    "#Unzip the file into the Data File \n",
    "unzip(\"Data/BLM.zip\", exdir=\"Data\")\n",
    "\n",
    "#Define the file path to the geodata base, if the BLM changes their file structure this will need to be updated \n",
    "fgdb=path.expand('Data/BLM_AIM_AquADat/v104/AquADat_data.gdb')\n",
    "\n",
    "#Read the Geodatabase layer into a file \n",
    "BLM <- data.frame(readOGR(dsn=fgdb))\n",
    "\n",
    "#write the datafile to the datafile in the repository\n",
    "write.csv(BLM,\"Data/BLM.csv\")\n",
    "\n",
    "head(BLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EMA Rivers and Streams Data </h3>\n",
    "EPA collects data across the Unites States and publised their metric level data here!!!!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'RCurl' is in use and will not be installed\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'tidyverse' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\rscully\\AppData\\Local\\Temp\\1\\RtmpgTjMrL\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tidyverse' was built under R version 3.6.2\"-- Attaching packages --------------------------------------- tidyverse 1.3.0 --\n",
      "v ggplot2 3.2.1     v purrr   0.3.3\n",
      "v tibble  2.1.3     v dplyr   0.8.3\n",
      "v tidyr   1.0.0     v stringr 1.4.0\n",
      "v readr   1.3.1     v forcats 0.4.0\n",
      "-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x tidyr::complete() masks RCurl::complete()\n",
      "x dplyr::filter()   masks stats::filter()\n",
      "x dplyr::lag()      masks stats::lag()\n",
      "Warning message:\n",
      "\"package 'dplyr' is in use and will not be installed\""
     ]
    }
   ],
   "source": [
    "install.packages(\"RCurl\")\n",
    "library(RCurl)\n",
    "\n",
    "\n",
    "install.packages('tidyverse')\n",
    "library(tidyverse)\n",
    "\n",
    "install.packages(\"dplyr\")\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in function (type, msg, asError = TRUE) : Could not resolve host: https\n",
     "output_type": "error",
     "traceback": [
      "Error in function (type, msg, asError = TRUE) : Could not resolve host: https\nTraceback:\n",
      "1. getURL(\"https:/www.epa.gov/sites/production/files/2015-09/phabmed.csv\")",
      "2. curlPerform(curl = curl, .opts = opts, .encoding = .encoding)",
      "3. function (type, msg, asError = TRUE) \n . {\n .     if (!is.character(type)) {\n .         i = match(type, CURLcodeValues)\n .         typeName = if (is.na(i)) \n .             character()\n .         else names(CURLcodeValues)[i]\n .     }\n .     typeName = gsub(\"^CURLE_\", \"\", typeName)\n .     fun = (if (asError) \n .         stop\n .     else warning)\n .     fun(structure(list(message = msg, call = sys.call()), class = c(typeName, \n .         \"GenericCurlError\", \"error\", \"condition\")))\n . }(6L, \"Could not resolve host: https\", TRUE)"
     ]
    }
   ],
   "source": [
    " #Pull the data set for NRSA 0809 Physical Habitat Larger Set of Metrics - Data (CSV)(1 pg, 4 MB) from\n",
    "  #WEBPAGE https://www.epa.gov/national-aquatic-resource-surveys/data-national-aquatic-resource-surveys\n",
    "ld_download <- getURL(\"https:\\www.epa.gov\\sites\\production\\files\\2015-09\\phabmed.csv)\n",
    "\n",
    "ld_download <- getURL(\"https:/www.epa.gov/sites/production/files/2015-09/phabmed.csv\")\n",
    "  \n",
    "  large_data  <- tbl_df(read.csv (text=ld_download))\n",
    "  \n",
    "  #Load the list of metric names create from the metadata \n",
    "  subSN<- read.csv(\"Data/SubSetOfMetricNames.csv\") \n",
    "  \n",
    "  #A vector of metric names from the EPA data \n",
    "  EPA<-subSN$EPAColumn\n",
    "  EPA<-as.character(EPA[!is.na(EPA)])\n",
    "  \n",
    "  # Include the protocol variable because the dataset contains both Wadeable and Boat streams, we are only intrested in wadeable streams \n",
    "  EPA<- c(EPA, \"PROTOCOL\")\n",
    "  \n",
    "  #Create a subset of the EPA data sets with only the metrics that overlap between the programs \n",
    "  sub= large_data[c(EPA)]\n",
    "  \n",
    "  #Remove all botable data, creating a subset of data that only contains the wadable stream data protocol \n",
    "  EPA_Wadeable= filter(sub, sub$PROTOCOL==\"WADEABLE\")\n",
    "  #Save the dataset in the repository data file \n",
    "  write.csv(EPA_Wadeable, file=\"Data/EPA_Subset.csv\", row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##One Data Frame\n",
    "For mapping and analysis we build one dataframe with all data sourcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"Code/data_organize/creating one dataframe_for loop.R\")\n",
    "one_data_frame()\n",
    "data<- read.csv(\"Data/All_Data.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data %>%\n",
    "  group_by(Program) %>%\n",
    "  summarize(mean(PctPool, na.rm=T)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
