---
title: "BAP"
output:
  word_document: default
  pdf_document: default
  html_notebook: default
---


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 


```{r global, include=FALSE}

#install.packages("leaflet")
#install.packages("sp")
#install.packages("sf")
#install.packages("tidyverse")
install.packages("rgdal")
#install.packages("formattable")
#install.packages("kableExtra")
install.packages("DT")

library(openxlsx)
library(downloader) 
library(leaflet)
library(sp)
library(sf)
library(tidyverse)
library(rgdal)

library(rstudioapi)
install.packages("RCurl")
library(RCurl)
library(ggplot2)
library(formattable)
library(htmltools)

#Packages to create well formated tables in RStuido 
library(knitr)
library(DT)
library(gridExtra)
library(kableExtra)

install.packages("xlsx")
library("xlsx")

```

<h1>Background </h1>

To accelerate research and decision making data needs to be findable, accessible, interoperable, and reusable (FAIR). Multiple federal, state and tribal agencies collect in-stream and riparian habitat metrics to answer management questions specific to their program goals. This analysis package integrates data from two different aquatic monitoring programs; BLM AIM and EPA Rivers and Streams (Table1) . We would like to integrate two US Forest Service in-stream aquatic habitat monitoring programs, but their data is not publicity accessible. 

<h2>Monitoring Program Information</h2> 


```{r}
#install.packages("xlsx")
#library(xlsx)

program_info<-(read.xlsx("Data/Metadata.xlsx", 1))
head(program_info)


#kable(program_info) %>%
 #   kable_styling(bootstrap_options = c("striped", "hover", fixed_header=TRUE ))

```

<h3> Program Metrics </h3> 
Each monitoring program calculates a standard set of metrics based on their user's needs. Metadata for the EPA and BLM can be found on their webpages, PIBO and AREMP is aviable apon request. To facilitate data sharing we compiled a data dictionary identifing the metrics calculate by more then one program. You can find the full metric table in !!!! (NEED TO REVIEW AND PUBLISH) We classified each metirc into a catagory, table 2 shows the count of metrics by catagory. 

```{r}

#Read in the data dictionary 
metadata <-as_tibble(read.xlsx("Data/Metadata.xlsx", 2))

kable(metadata %>%
  group_by(Category)%>%
  count(Category, sort=TRUE))


```

Each program calculates a produce a standard set of metrics. The EPA, BLM data and metadata is publicaly av
```{r}
source("Code/data_organize/create_list_of_metrics.R")
metrics_list=metrics()
kable(metrics_list)%>%
    kable_styling(bootstrap_options = c("striped", "hover", fixed_header=TRUE ))
```

<h1>Data Sources</h1> 
<h2>Metric Data</h2>
Two of the four habitat programs store metric level data online. We pull that data from the sourcs to be used to create a singular data set for mapping and analysis. 

<h3> BLM AIM Data </h3>
The BLM AIM collects data across BLM lands. BLM data is stored as a geodatabase at !!!!!!!. 


```{r}

#URL Location of the AIM GeoDataBase if the location changes this will need to be updated 
fileURL<- "https://gis.blm.gov/AIMDownload/LayerPackages/BLM_AIM_AquADat.zip"

#Download the file to the Data file
download(fileURL, "Data/BLM.zip" )

#Unzip the file into the Data File 
unzip("Data/BLM.zip", exdir="Data")

#Define the file path to the geodata base, if the BLM changes their file structure this will need to be updated 
fgdb=path.expand('Data/BLM_AIM_AquADat/v104/AquADat_data.gdb')

#Read the Geodatabase layer into a file 
BLM <- data.frame(readOGR(dsn=fgdb))

#write the datafile to the datafile in the repository
write.csv(BLM,"Data/BLM.csv")

head(BLM)
```
<h3>EMA Rivers and Streams Data </h3>
EPA collects data across the Unites States and publised their metric level data here!!!!!!! 

```{r}
#source("Code/data_organize/Pull EPA Data.R")
#Fuction to pull EPA data from the user assigned webpage, clean, save and organize the wadable stream data
#This does now work when connect to the vpn (I HAVE NO IDEA WHY?)
#Pull_EPA("https://www.epa.gov/sites/production/files/2015-09/phabmed.csv") 

```


<h1>One Data Frame</h1>
For mapping and analysis we build one dataframe with all data sourcs. 

```{r}
source("Code/data_organize/creating one dataframe_for loop.R")
one_data_frame()
data<- read.csv("Data/All_Data.csv") 
```

<h1>Map</h1>
Identify where data is collected for each program. (ideally we would create an inateractive map allowing the user to define the area they are intrested in data for)

```{r}
map_dir = paste0(getwd(),"/Map")
htmlMap<- file.path(map_dir, "map.html")
viewer(htmlMap) 
```

<h1>Data Collection and Anaysis Methods</h1>
Based on proffessional opinion we identify in the data dictionary which metrics are similary, but inorder to understand how the data is collected and anaysised we need to see read the methodology. (PULL THE METHODOLOGY FROM MR.org )
```{r}
metric = "PctPool"

# Pull Method data from MR.org based on the metric we are intrested in. 
#I DON'T KNOW HOW TO make the HTML look correct 
source("Code/data_organize/metric_documentation.R")
PctPoolMetadata <- metric_information("PctPool")
print(PctPoolMetadata)

kable(PctPoolMetadata)%>%
    kable_styling(bootstrap_options = c("striped", "hover", fixed_header=TRUE ))

```

<h1> Environmental Covariates</h1>



<h1>Simple Visualizations </h2>



```{r}
data %>%
  group_by(Program) %>%
  summarize(mean(PctPool, na.rm=T)) 

```
```{r}
ggplot(data, aes(x=Grad, y=PctPool))+ geom_point()+facet_wrap(~Program)

```
```{r}
data %>%
  group_by(Program) %>%
  summarize(mean(PctPool, na.rm=T))
```
```{r}
ggplot(data, aes(PctPool))+geom_histogram()+facet_wrap(~Program)
```

```{r}
#library(shiny)

#h = ggplot(data, aes(PctPool))+geom_histogram()

# Define UI for application that draws a histogram
#ui <- fluidPage(

  # App title ----
  #titlePanel("Pools"),

  # Sidebar layout with input and output definitions ----
  #sidebarLayout(

    # Sidebar panel for inputs ----
   # sidebarPanel(

      # Input: Slider for the number of bins ----
    #  sliderInput(inputId = "bins",
     #             label = "Number of bins:",
      #            min = min(data$PctPool, na.rm=T),
       #           max = max(data$PctPool, na.rm=T),
        #          value = 10)

    #),

    # Main panel for displaying outputs ----
#    mainPanel(

      # Output: Histogram ----
 #     plotOutput(outputId = "h")
#
 # )
#)

#ui
```
```{r}

```

