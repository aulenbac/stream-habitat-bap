---
title: "BAP"
output:
  html_notebook: default
  pdf_document: default
  word_document: default
---


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 


```{r global, include=FALSE}

#install.packages("leaflet")
#install.packages("sp")
#install.packages("sf")
#install.packages("tidyverse")
install.packages("rgdal")
#install.packages("formattable")
#install.packages("kableExtra")
install.packages("DT")

library(openxlsx)
library(downloader) 
library(leaflet)
library(sp)
library(sf)
library(tidyverse)
library(rgdal)

library(rstudioapi)
install.packages("RCurl")
library(RCurl)
library(ggplot2)
library(formattable)
library(htmltools)

#Packages to interact with ScienceBase 
install.packages("sbtools")
library(sbtools)

#Packages to create well formated tables in RStuido 
library(knitr)
library(DT)
library(gridExtra)
library(kableExtra)

install.packages("xlsx")
library("xlsx")

```

<h1>Background </h1>

To accelerate research and decision making data needs to be findable, accessible, interoperable, and reusable (FAIR). Multiple federal, state and tribal agencies collect in-stream and riparian habitat metrics to answer management questions specific to their program goals. This analysis package integrates data from two different aquatic monitoring programs; BLM AIM and EPA Rivers and Streams (Table1) . We would like to integrate two US Forest Service in-stream aquatic habitat monitoring programs, but their data is not publicity accessible. 

<h2>Monitoring Program Information</h2> 


```{r}
install.packages("readxl")
library(readxl)

program_info <- (read_excel("Data/Metadata.xlsx", 1))
head(program_info)


#kable(program_info) %>%
 #   kable_styling(bootstrap_options = c("striped", "hover", fixed_header=TRUE ))

```

<h3> Program Metrics </h3> 
Each monitoring program calculates a standard set of metrics based on their user's needs. Metadata for the EPA and BLM can be found on their webpages, PIBO and AREMP is aviable apon request. To facilitate data sharing we compiled a data dictionary identifing the metrics calculate by more then one program. You can find the full metric table in !!!! (NEED TO REVIEW AND PUBLISH) We classified each metirc into a catagory, table 2 shows the count of metrics by catagory. 

```{r}

#Read in the data dictionary 
metadata <-as_tibble(read.xlsx("Data/Metadata.xlsx", 2))

kable(metadata %>%
  group_by(Category)%>%
  count(Category, sort=TRUE))


```

Each program calculates a produce a standard set of metrics. The EPA, BLM data and metadata is publicaly av
```{r}
source("Code/data_organize/create_list_of_metrics.R")
metrics_list=metrics()
kable(metrics_list)%>%
    kable_styling(bootstrap_options = c("striped", "hover", fixed_header=TRUE ))
```

<h1>Data Sources</h1> 
<h2>Metric Data</h2>
Three of the four habitat programs store metric level data online, each program stores data in a different and unique way, below is the code to  We pull that data from the sourcs to be used to create a singular data set for mapping and analysis. 

<h3> BLM AIM Data </h3>
The BLM AIM collects data across BLM lands


```{r}

library(sf)
library(tmap)
library(httr)
library(data.table)



url <- list(hostname = "gis.blm.gov/arcgis/rest/services",
  scheme = "https",
  path = "hydrography/BLM_Natl_AIM_AquADat/MapServer/0/query",
  query = list(
          where = "1=1",
          outFields = "*",
          returnGeometry = "true",
          f = "geojson")) %>% 
      setattr("class", "url")
request <- build_url(url)
BLM <- st_read(request) 

#write the datafile to the datafile in the repository
write.csv(BLM,"Data/BLM.csv")

head(BLM)
```
<h3>EMA Rivers and Streams Data </h3>
EPA collects data across the Unites States and publised their metric level data here!!!!!!! 

```{r}
#source("Code/data_organize/Pull EPA Data.R")
#Fuction to pull EPA data from the user assigned webpage, clean, save and organize the wadable stream data
#This does now work when connect to the vpn (I HAVE NO IDEA WHY?)
#Pull_EPA("https://www.epa.gov/sites/production/files/2015-09/phabmed.csv") 

```


<h1>One Data Frame</h1>
For mapping and analysis we build one dataframe with all data sourcs. 

```{r}
source("Code/data_organize/creating one dataframe_for loop.R")
one_data_frame()
data<- read.csv("Data/All_Data.csv") 
```

<h1>Map</h1>
Identify where data is collected for each program. (ideally we would create an inateractive map allowing the user to define the area they are intrested in data for)

```{r}
map_dir = paste0(getwd(),"/Map")
htmlMap<- file.path(map_dir, "map.html")
viewer(htmlMap) 
```

<h1>Data Collection and Anaysis Methods</h1>
Based on proffessional opinion we identify in the data dictionary which metrics are similary, but inorder to understand how the data is collected and anaysised we need to see read the methodology. (PULL THE METHODOLOGY FROM MR.org )
```{r}
metric = "PctPool"

# Pull Method data from MR.org based on the metric we are intrested in. 
#I DON'T KNOW HOW TO make the HTML look correct 
source("Code/data_organize/metric_documentation.R")
PctPoolMetadata <- metric_information("PctPool")
print(PctPoolMetadata)

kable(PctPoolMetadata)%>%
    kable_styling(bootstrap_options = c("striped", "hover", fixed_header=TRUE ))

```

<h1> Environmental Covariates</h1>



<h1>Simple Visualizations </h2>



```{r}
data %>%
  group_by(Program) %>%
  summarize(mean(PctPool, na.rm=T)) 

```
```{r}
ggplot(data, aes(x=Grad, y=PctPool))+ geom_point()+facet_wrap(~Program)

```
```{r}
data %>%
  group_by(Program) %>%
  summarize(mean(PctPool, na.rm=T))
```
```{r}
ggplot(data, aes(PctPool))+geom_histogram()+facet_wrap(~Program)
```
<h1> Explore In Stream Tributary Habitat Data</h1>

As a proof of concept for this analysis package, we picked 2-3 metrics (category of metrics?) as a test case to build a data dictionary, intergrade data from multiple sources and design infrastructure to serve data to interested parties. We selected metrics that are responsive to management decisions, have low measure error as defined in the lititure (Kershner and Roper 2010, ##add other references), the method comparison (insert link ) work completed by this group. Special consideration was given to metrics identified in the speed dating exercise speed dating exercise as of high importance by the three programs.
```{r}
wd <- getwd()
file<- paste0(wd,"/Code/Visualization/Shiney_map_reactive_tabs.R")
source(file)
map_download()
```
```{r}

```

