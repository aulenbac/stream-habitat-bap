---
title: "BAP"
output: html_notebook
---


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 


```{r}

#install.packages("leaflet")
#install.packages("sp")
#install.packages("sf")
#install.packages("tidyverse")
#install.packages("rgdal")
#install.packages("formattable")
#install.packages("kableExtra")

library(openxlsx)
library(downloader) 
library(leaflet)
library(sp)
library(sf)
library(tidyverse)
library(rgdal)
library(rstudioapi)
library(RCurl)
library(ggplot2)
library(formattable)
library(htmltools)

#Packages to create well formated tables in RStuido 
library(knitr)
library(gridExtra)
library(kableExtra)

```
Background information check 
```{r}
rm (list = objects ()); ls ()
my.d <- rstudioapi::getActiveDocumentContext()
print(my.d)
my.dir <- dirname(my.file.location)
print(my.dir)
```

<h1>Background </h1>

To accelerate research and decision making data needs to be findable, accessible, interoperable, and reusable (FAIR). Multiple federal, state and tribal agencies collect in-stream and riparian habitat metrics to answer management questions specific to their program goals. This anaysis package intergrates data from two different aquatic monitoring programs; BLM AIM and EPA Rivers and Streams (Table1) . Ultemently we would like to intergrate two US Forest Service instream aquatic habitat monitoring programs, but their data is not publicially accessable. 

<h2>Monitoirng Program Information</h2> 


```{r}
program_info<-(read.xlsx("Data/Metadata.xlsx", 1))

kable(program_info) %>%
    kable_styling(bootstrap_options = c("striped", "hover", fixed_header=T ))
```

<h3> Program Metrics </h3> 
Each monitoring program calculates a standard set of metrics based to  we compiled a data dictionary indtifing where programs calculate the same metrics. We classified each metirc into a catagory, table 2 shows the count of metrics by catagory. 

```{r}

#Read in the data dictionary 
metadata <-as_tibble(read.xlsx("Data/Metadata.xlsx", 2))

metadata %>%
  group_by(Category)%>%
  count(Category)
```

Using the dictionary we indtify the metrics calculated by 4 or more programs. 
```{r}
source("Code/data_orginize/create_list_of_metrics.R")
metrics_list=metrics()

```

<h1>Data Sources</h1> 
<h2>Metric Data</h2>
Two of the four habitat programs store metric level data online. We pull that data from the sourcs to be used to create a singular data set for mapping and analysis. 

<h3> BLM AIM Data </h3>
The BLM AIM collects data across BLM lands. BLM data is stored as a geodatabase at !!!!!!!. 


```{r}

#URL Location of the AIM GeoDataBase if the location changes this will need to be updated 
fileURL<- "https://gis.blm.gov/AIMDownload/LayerPackages/BLM_AIM_AquADat.zip"

#Download the file to the Data file
download(fileURL, "Data/BLM.zip" )

#Unzip the file into the Data File 
unzip("Data/BLM.zip", exdir="Data")

#Define the file path to the geodata base, if the BLM changes their file structure this will need to be updated 
fgdb=path.expand('Data/BLM_AIM_AquADat/v104/AquADat_data.gdb')

#Read the Geodatabase layer into a file 
BLM <- data.frame(readOGR(dsn=fgdb))

#write the datafile to the datafile in the repository
write.csv(BLM,"Data/BLM.csv")

head(BLM)
```
<h3>EMA Rivers and Streams Data </h3>
EPA collects data across the Unites States and publised their metric level data here!!!!!!! 

```{r}
source("Code/data_orginize/Pull EPA Data.R")
#Fuction to pull EPA data from the user assigned webpage, clean, save and orginize the wadable stream data
#This does now work when connect to the vpn (I HAVE NO IDEA WHY?)
Pull_EPA("https://www.epa.gov/sites/production/files/2015-09/phabmed.csv") 

```


<h1>One Data Frame</h1>
For mapping and analysis we build one dataframe with all data sourcs. 

```{r}
source("Code/data_orginize/creating one dataframe_for loop.R")
one_data_frame()
data<- read.csv("Data/All_Data.csv") 
```

<h1>Map</h1>
Identify where data is collected for each program. (ideally we would create an inateractive map allowing the user to define the area they are intrested in data for)

```{r}
map_dir = paste0(getwd(),"/Map")
htmlMap<- file.path(map_dir, "map.html")
viewer(htmlMap) 
```


<h1>Data Collection and Anaysis Methods</h1>
Based on proffessional opinion we identify in the data dictionary which metrics are similary, but inorder to understand how the data is collected and anaysised we need to see read the methodology. (PULL THE METHODOLOGY FROM MR.org )
```{r}

library(jsonlite)

# Pull Method data from MR.org based on the metric we are intrested in. 
#I DON'T KNOW HOW TO make the HTML look correct 


id=922
mr_method= paste0("https://www.monitoringresources.org/api/v1/methods/", id) 
mr_method=URLencode(mr_method)
method_text=fromJSON(mr_method) 
kable(method_text$instructions)


```

<h1> Environmental Covariates</h1>



<h1>Simple Visulizations </h2>



```{r}
data %>%
  group_by(Program) %>%
  summarize(mean(PctPool, na.rm=T)) 

```
```{r}
ggplot(data, aes(x=Grad, y=PctPool))+ geom_point()+facet_wrap(~Program)


```
```{r}
data %>%
  group_by(Program) %>%
  summarize(mean(PctPool, na.rm=T))
```
```{r}
ggplot(data, aes(PctPool))+geom_histogram()+facet_wrap(~Program)
```

```{r}
library(shiny)

h = ggplot(data, aes(PctPool))+geom_histogram()

# Define UI for application that draws a histogram
ui <- fluidPage(

  # App title ----
  titlePanel("Hello Shiny!"),

  # Sidebar layout with input and output definitions ----
  sidebarLayout(

    # Sidebar panel for inputs ----
    sidebarPanel(

      # Input: Slider for the number of bins ----
      sliderInput(inputId = "bins",
                  label = "Number of bins:",
                  min = min(data$PctPool, na.rm=T),
                  max = max(data$PctPool, na.rm=T),
                  value = 10)

    ),

    # Main panel for displaying outputs ----
    mainPanel(

      # Output: Histogram ----
      plotOutput(outputId = "h")

    )
  )
)

ui
```

